{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE FOLLOWING CODE SCANS THE DATASET AND COUNTS THE AMOUNT OF FILE PRESENT#\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#SAMPLE RATE FOR AUDIO PLAYBACK#\n",
    "samplerate = 16000\n",
    "\n",
    "#CHECK THE FOLDER, RETURN ERROR IF NOT FOUND#\n",
    "data_dir = pathlib.Path('Project Dataset')\n",
    "if not data_dir.exists():\n",
    "  print(\"Dataset Not Found\")\n",
    "else:\n",
    "  print(\"Dataset\", data_dir ,\"Found!\")\n",
    "\n",
    "#LOOK FOR MIDI FILES, COUNT THE TOTAL AMOUNT OF MIDI FILES#\n",
    "filenames = glob.glob(str(data_dir/'*.mid*'))\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PULL A FILE FROM THE DATA SET AND PLAY IT, LABEL THE INSTRUMENT USED AND THE NOTES PLAYED#\n",
    "\n",
    "sample_file = filenames[23]\n",
    "print(\"File Sampled:\",sample_file)\n",
    "pm = pretty_midi.PrettyMIDI(sample_file) #LOAD THE FILE INTO A PRETTY MIDI OBJECT#\n",
    "endtime = round(pm.get_end_time(), 0)\n",
    "length = int(endtime) #FETCH FILE LENGTH FOR PARSING LATER, MUST BE AN INTEGER TO AVOID KERNEL ERRORS\n",
    "print(\"File Is\",endtime,\"Seconds\")\n",
    "#DEFINE A SUBROUTINE TO DISPLAY THE AUDIO FILE#\n",
    "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=length): #PROGRAM KNOWS HOW LONG TO SET THE FILE\n",
    "  waveform = pm.fluidsynth(fs=samplerate)\n",
    "  waveform_short = waveform[:seconds*samplerate]\n",
    "  return display.Audio(waveform_short, rate=samplerate)\n",
    "\n",
    "#FIND THE INSTRUMENTS, COUNT AND DEFINE THEM#\n",
    "print(\"Number Of Instruments:\", len(pm.instruments))\n",
    "instrument = pm.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "print(\"Instrument Used:\", instrument_name)\n",
    "\n",
    "#ESTIMATE THE TEMPO OF THE MUSIC#\n",
    "tempo = pm.estimate_tempo()\n",
    "tempo_rounded = round(tempo, 0)\n",
    "print(\"File Tempo:\", tempo_rounded,\"Bpm\")\n",
    "\n",
    "#FIND THE NOTES USED IN THE MUSIC#\n",
    "for i, note in enumerate(instrument.notes[:10]):\n",
    "  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
    "  duration = note.end - note.start\n",
    "  print(f'{i}: pitch={note.pitch}, note_name={note_name},'\n",
    "        f' duration={duration:.4f}')\n",
    "\n",
    "#CONVERT THE MIDI TO NOTES THAT ARE PLAYABLE#\n",
    "listNotes = np.zeros(1)\n",
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    instrument = pm.instruments[0]\n",
    "    notes = collections.defaultdict(list)\n",
    "\n",
    "#SORT THE NOTES INTO START TIME ORDER#\n",
    "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "    prev_start = sorted_notes[0].start\n",
    "    for note in sorted_notes:\n",
    "        start = note.start\n",
    "        end = note.end\n",
    "        notes['pitch'].append(note.pitch)\n",
    "        notes['start'].append(start)\n",
    "        notes['end'].append(end)\n",
    "        notes['step'].append(start - prev_start)\n",
    "        notes['duration'].append(end - start)\n",
    "        prev_start = start\n",
    "    return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "raw_notes = midi_to_notes(sample_file)\n",
    "array = np.zeros(1)\n",
    "dataArray = midi_to_notes(sample_file)\n",
    "notename = np.zeros(1)\n",
    "df = pd.DataFrame({'Note':(dataArray.pitch)}, index=[0])\n",
    "dataArray.pitch.to_csv('Raw Data.csv', index=True)\n",
    "np.savetxt('pitch.csv',dataArray.pitch)\n",
    "raw_notes.head()\n",
    "display_audio(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT GRAPHS#\n",
    "\n",
    "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
    "  if count:\n",
    "    title = f'First {count} notes'\n",
    "  else:\n",
    "    title = f'Whole track'\n",
    "    count = len(notes['pitch'])\n",
    "  plt.figure(figsize=(20, 4))\n",
    "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
    "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
    "  plt.plot(\n",
    "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
    "  plt.xlabel('Time [s]')\n",
    "  plt.ylabel('Pitch')\n",
    "  _ = plt.title(title)\n",
    "\n",
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "  instrument = pm.instruments[0]\n",
    "  notes = collections.defaultdict(list)\n",
    "\n",
    "  # Sort the notes by start time\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "  prev_start = sorted_notes[0].start\n",
    "\n",
    "  for note in sorted_notes:\n",
    "    start = note.start\n",
    "    end = note.end\n",
    "    notes['pitch'].append(note.pitch)\n",
    "    notes['start'].append(start)\n",
    "    notes['end'].append(end)\n",
    "    notes['step'].append(start - prev_start)\n",
    "    notes['duration'].append(end - start)\n",
    "    notes['notes'].append(notes)\n",
    "    prev_start = start\n",
    "\n",
    "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "plot_piano_roll(raw_notes, count=200)\n",
    "plot_piano_roll(raw_notes)\n",
    "\n",
    "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
    "  plt.figure(figsize=[15, 5])\n",
    "  plt.subplot(1, 3, 1)\n",
    "  sns.histplot(notes, x=\"pitch\", bins=20)\n",
    "\n",
    "  plt.subplot(1, 3, 2)\n",
    "  max_step = np.percentile(notes['step'], 100 - drop_percentile)\n",
    "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))\n",
    "\n",
    "  plt.subplot(1, 3, 3)\n",
    "  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)\n",
    "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))\n",
    "plot_distributions(raw_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE FILE USING SKLEARN#\n",
    "df2 = pd.read_csv(\"Raw Data.csv\")\n",
    "df2.head()\n",
    "X = df2.drop('pitch', axis = 1)\n",
    "y = df2['pitch']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n",
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictionsRFC = rfc.predict(X_test)\n",
    "print(predictionsRFC)\n",
    "confMatRFC = confusion_matrix(y_test, predictionsRFC, labels = rfc.classes_) \n",
    "print(\" \")\n",
    "print(\"Confusion matrix: \\n\",confMatRFC)\n",
    "print(\" \")\n",
    "print(\"Plot of confusion matrix:\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = confMatRFC, display_labels = rfc.classes_)\n",
    "np.savetxt('Predicted Pitch.csv',predictionsRFC)\n",
    "disp.plot()\n",
    "dir(disp)\n",
    "#LSTM LIKELY A BETTER OPTION, MANY TREES DOESN'T PREDICT WELL#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTSM ATTEMPT TO EXTRACT PITCH AND DURATION#\n",
    "sample_file2 = filenames[23]\n",
    "print(\"File Sampled:\",sample_file2)\n",
    "pm = pretty_midi.PrettyMIDI(sample_file2) #LOAD THE FILE INTO A PRETTY MIDI OBJECT#\n",
    "endtime = round(pm.get_end_time(), 0)\n",
    "length = int(endtime) #FETCH FILE LENGTH FOR PARSING LATER, MUST BE AN INTEGER TO AVOID KERNEL ERRORS\n",
    "print(\"File Is\",endtime,\"Seconds\")\n",
    "#DEFINE A SUBROUTINE TO DISPLAY THE AUDIO FILE#\n",
    "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=length): #PROGRAM KNOWS HOW LONG TO SET THE FILE\n",
    "  waveform = pm.fluidsynth(fs=samplerate)\n",
    "  waveform_short = waveform[:seconds*samplerate]\n",
    "  return display.Audio(waveform_short, rate=samplerate)\n",
    "\n",
    "#FIND THE INSTRUMENTS, COUNT AND DEFINE THEM#\n",
    "print(\"Number Of Instruments:\", len(pm.instruments))\n",
    "instrument = pm.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "print(\"Instrument Used:\", instrument_name)\n",
    "\n",
    "#ESTIMATE THE TEMPO OF THE MUSIC#\n",
    "tempo = pm.estimate_tempo()\n",
    "tempo_rounded = round(tempo, 0)\n",
    "print(\"File Tempo:\", tempo_rounded,\"Bpm\")\n",
    "\n",
    "#CONVERT THE MIDI TO NOTES THAT ARE PLAYABLE#\n",
    "listNotes = np.zeros(1)\n",
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    instrument = pm.instruments[0]\n",
    "    notes = collections.defaultdict(list)\n",
    "\n",
    "#SORT THE NOTES INTO START TIME ORDER#\n",
    "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "    prev_start = sorted_notes[0].start\n",
    "    for note in sorted_notes:\n",
    "        start = note.start\n",
    "        end = note.end\n",
    "        notes['pitch'].append(note.pitch)\n",
    "        notes['start'].append(start)\n",
    "        notes['end'].append(end)\n",
    "        notes['step'].append(start - prev_start)\n",
    "        notes['duration'].append(end - start)\n",
    "        prev_start = start\n",
    "    return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "raw_notes = midi_to_notes(sample_file2)\n",
    "array = np.zeros(1)\n",
    "dataArray = midi_to_notes(sample_file2)\n",
    "notename = np.zeros(1)\n",
    "df = pd.DataFrame({'Note':(dataArray.pitch)}, {'Duration':(dataArray.duration)})\n",
    "dataArray.pitch.to_csv('Raw Data.csv', index=True)\n",
    "np.savetxt('ltsm.csv', np.c_[dataArray.pitch, dataArray.duration, dataArray.start, dataArray.end, dataArray.step], delimiter=',', header = 'Pitch,Duration,Start,End,Step', comments='', fmt='%1.2f')\n",
    "#PROGRAM HAS NOW SAVED DATA OF THE FILE TO A CSV#\n",
    "print(\"Data Extracted Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm.csv', usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "np.savetxt('ltsm (predicted).csv', np.c_[testPredict], delimiter=',', header = 'Predicted Duration', comments='', fmt='%1.2f')\n",
    "# SAVE np.c_[testPredict] AS DIFFERENT VARIABLE EACH TIME#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTEMPT TO TRAIN OTHER ASPECTS IN ORDER TO CREATE A FULL SONG#\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm.csv', usecols=[0], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict2 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict2 = scaler.inverse_transform(testPredict2)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict2[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict2\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm.csv', usecols=[2], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict3 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict3 = scaler.inverse_transform(testPredict3)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict3[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict3\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preDur = np.c_[testPredict]\n",
    "prePit = np.c_[testPredict2]\n",
    "preSta = np.c_[testPredict3]\n",
    "np.savetxt('ltsm (predicted).csv',np.hstack([preDur,prePit,preSta]), delimiter=',', header = 'Predicted Duration, Predicted Pitch, Predicted Start', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm.csv', usecols=[3], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict4 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict4 = scaler.inverse_transform(testPredict4)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict4[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict4\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preDur = np.c_[testPredict]\n",
    "prePit = np.c_[testPredict2]\n",
    "preSta = np.c_[testPredict3]\n",
    "preEnd = np.c_[testPredict4]\n",
    "np.savetxt('ltsm (predicted).csv',np.hstack([preDur,prePit,preSta,preEnd]), delimiter=',', header = 'Predicted Duration, Predicted Pitch, Predicted Start, Predicted End', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm.csv', usecols=[4], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict5 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict5 = scaler.inverse_transform(testPredict5)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict5[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict5\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preDur = np.c_[testPredict]\n",
    "prePit = np.c_[testPredict2]\n",
    "preSta = np.c_[testPredict3]\n",
    "preEnd = np.c_[testPredict4]\n",
    "preSte = np.c_[testPredict5]\n",
    "np.savetxt('ltsm (predicted).csv',np.hstack([preDur,prePit,preSta,preEnd,preSte]), delimiter=',', header = 'Predicted Duration, Predicted Pitch, Predicted Start, Predicted End, Predicted Step', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ltsm (predicted).csv',np.hstack([preDur,prePit,(preSta-preSta[0]),(preEnd-preEnd[0]),preSte]), delimiter=',', header = 'duration,pitch,start,end,step', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = pandas.read_csv('ltsm (predicted).csv', engine='python')\n",
    "def notes_to_midi(\n",
    "  notes: DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm\n",
    "print(DataFrame)\n",
    "example_file = 'example.midi'\n",
    "example_pm = notes_to_midi(\n",
    "    DataFrame, out_file=example_file, instrument_name=instrument_name)\n",
    "PrettyMIDI(midi_file = 'example.midi', resolution = 220, initial_tempo = 80)\n",
    "display_audio(example_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_piano_roll(DataFrame, count=200)\n",
    "plot_piano_roll(DataFrame)\n",
    "plot_distributions(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING THIS TAKES A LONG TIME#\n",
    "num_files = len(filenames)\n",
    "all_notes = []\n",
    "for f in filenames[:num_files]:\n",
    "  notes = midi_to_notes(f)\n",
    "  all_notes.append(notes)\n",
    "\n",
    "all_notes = pd.concat(all_notes)\n",
    "print(all_notes)\n",
    "np.savetxt('ltsm(completed).csv', all_notes, delimiter=',', header = 'Pitch,Duration,Start,End,Step', comments='', fmt='%1.2f')\n",
    "print(\"All Data Extracted Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#WARNING THIS CELL TAKES A VERY LONG TIME TO RUN! ONLY RUN THIS ON A POWERFUL PC#\n",
    "\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[0], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict2 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict2 = scaler.inverse_transform(testPredict2)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict2[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict2\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[3], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict4 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict4 = scaler.inverse_transform(testPredict4)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict4[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict4\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[4], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict5 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict5 = scaler.inverse_transform(testPredict5)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict5[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict5\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preDur = np.c_[testPredict]\n",
    "prePit = np.c_[testPredict2]\n",
    "preSta = np.c_[testPredict3]\n",
    "preEnd = np.c_[testPredict4]\n",
    "preSte = np.c_[testPredict5]\n",
    "\n",
    "np.savetxt('ltsm (predicted complete).csv',np.hstack([preDur,prePit,(preSta-preSta[0]),(preEnd-preEnd[0]),preSte]), delimiter=',', header = 'duration,pitch,start,end,step', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW IS EACH CELL FOR TRAINING THE DATASET IN INDIVIDUAL PIECES, BETTER FOR PC'S WITH LESS RAM#\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preDur = np.c_[testPredict]\n",
    "np.savetxt('ltsm (predicted duration).csv', np.c_[testPredict], delimiter=',', header = 'Predicted Duration', comments='', fmt='%1.2f')\n",
    "# SAVE np.c_[testPredict] AS DIFFERENT VARIABLE EACH TIME#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[0], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict2 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict2 = scaler.inverse_transform(testPredict2)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict2[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict2\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "prePit = np.c_[testPredict2]\n",
    "np.savetxt('ltsm (predicted pitch).csv', np.c_[testPredict2], delimiter=',', header = 'Predicted Duration', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[2], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict3 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict3 = scaler.inverse_transform(testPredict3)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict3[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict3\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preSta = np.c_[testPredict3]\n",
    "np.savetxt('ltsm (predicted start).csv',np.c_[testPredict3], delimiter=',', header = 'Predicted Start', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[3], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict4 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict4 = scaler.inverse_transform(testPredict4)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict4[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict4\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preEnd = np.c_[testPredict4]\n",
    "np.savetxt('ltsm (predicted end).csv',np.c_[testPredict4], delimiter=',', header = 'Predicted End', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#LOAD THE DATA FOR LEARNING WITH#\n",
    "dataframe = pandas.read_csv('ltsm(completed).csv', usecols=[4], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "numpy.random.seed(seed) #NEED TO FIX THE RANDOM NUMBER, MAKES THE RESULTS REPRODUCIBLE#\n",
    "\n",
    "#NORMALISE THE DATA FROM 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#TRAIN 70% OF THE DATA, LEAVING 30 FOR TESTING\n",
    "train_size = int(len(dataset) * 0.70) #THIS NEEDS CHANGING, IT'S ONLY TRAINING THE LAST 30% OF START#\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print('Amount of data for training:',len(train),',', 'Amount of data for testing:',len(test))\n",
    "\n",
    "#DATASET CREATION, LOOK_BACK VALUE DEFINES HOW FAR AHEAD IT PREDICTS, Eg// X = DURATION AND GIVEN PITCH AND Y IS DURATION AT PITCH + LOOK_BACK\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#RESHAPE THE DATAFRAME\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#SHAPE TO: SAMPLES, TIME STEP, FEATURES\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#CREATE AND FIT THE LTSM\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2) \n",
    "\n",
    "#PREDICT\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict5 = model.predict(testX)\n",
    "\n",
    "#INVERT\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict5 = scaler.inverse_transform(testPredict5)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "#RMS ERROR\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict5[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#GET PREDICTIONS READY FOR PLOTTING\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict5\n",
    "\n",
    "#PLOT THE BASE DATA ALONG WITH PREDICTED DATA\n",
    "plt.figure(figsize = (20, 6))\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "preSte = np.c_[testPredict5]\n",
    "np.savetxt('ltsm (predicted step).csv',np.c_[testPredict5], delimiter=',', header = 'Predicted Step', comments='', fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINE THE TRAINED FILES INTO ONE CSV\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "df[\"duration\"] = pd. read_csv(\"ltsm (predicted duration).csv\")\n",
    "df.to_csv(\"combined.csv\", index=False)\n",
    "df[\"pitch\"] = pd. read_csv(\"ltsm (predicted pitch).csv\")\n",
    "df.to_csv(\"combined.csv\", index=False)\n",
    "df[\"start\"] = pd. read_csv(\"ltsm (predicted start).csv\")\n",
    "df.to_csv(\"combined.csv\", index=False)\n",
    "df[\"end\"] = pd. read_csv(\"ltsm (predicted end).csv\")\n",
    "df.to_csv(\"combined.csv\", index=False)\n",
    "df[\"step\"] = pd. read_csv(\"ltsm (predicted step).csv\")\n",
    "df.to_csv(\"combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE THE FINAL MIDI FILE, ONLY USING THE FIRST 20,000 ENTRIES TO SAVE TIME AND CUT DOWN THE FILE LENGTH\n",
    "DataFrame = pd.read_csv('combined.csv', engine='python', nrows = 20000)\n",
    "def notes_to_midi(\n",
    "  notes: DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm\n",
    "print(DataFrame)\n",
    "example_file = 'final.midi'\n",
    "example_pm = notes_to_midi(\n",
    "    DataFrame, out_file=example_file, instrument_name=instrument_name)\n",
    "display_audio(example_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_piano_roll(DataFrame, count=200)\n",
    "plot_piano_roll(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = pd.read_csv('combined.csv', engine='python')\n",
    "def notes_to_midi(\n",
    "  notes: DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm\n",
    "print(DataFrame)\n",
    "example_file = 'final full.midi'\n",
    "example_pm = notes_to_midi(\n",
    "    DataFrame, out_file=example_file, instrument_name=instrument_name)\n",
    "display_audio(example_pm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
